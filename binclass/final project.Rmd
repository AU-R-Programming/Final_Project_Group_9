---
title: "final_project_group9"
output: html_document
date: "2024-12-05"
---


```{r}



# Final Project

## Step 1: Created R package - complete (aka: binclass)


# Step 2: Implement Core Functionality

## 1. Logistic regression using numerical optimization
logistic_regression <- function(X, y, tol = 1e-6, max_iter = 100) {
  # X: matrix of predictors (n x p)
  # y: response vector (n x 1)
  # tol: tolerance for convergence
  # max_iter: maximum iterations for the optimization

  # Initial values for beta from least squares estimate
  X_t <- t(X)
  beta_init <- solve(X_t %*% X) %*% X_t %*% y

  # Sigmoid function
  sigmoid <- function(x) {
    1 / (1 + exp(-x))
  }

  # Negative log-likelihood function
  nll <- function(beta) {
    p <- sigmoid(X %*% beta)
    -sum(y * log(p) + (1 - y) * log(1 - p))
  }

  # Gradient of the negative log-likelihood
  gradient <- function(beta) {
    p <- sigmoid(X %*% beta)
    grad <- t(X) %*% (y - p)
    return(grad)
  }

  # Use optim() function for numerical optimization
  result <- optim(beta_init, nll, gr = gradient, method = "BFGS", control = list(maxit = max_iter, reltol = tol))

  return(result$par) # The estimated beta
}

## 2. Bootstrapped Confidence Intervals
bootstrap_CI <- function(X, y, n_bootstrap = 20, alpha = 0.05) {
  n <- nrow(X)
  boot_betas <- matrix(NA, nrow = n_bootstrap, ncol = ncol(X))

  for (i in 1:n_bootstrap) {
    sample_indices <- sample(1:n, replace = TRUE)
    X_boot <- X[sample_indices, , drop = FALSE]
    y_boot <- y[sample_indices]

    boot_betas[i, ] <- logistic_regression(X_boot, y_boot)
  }

  # Calculate the lower and upper percentiles for CI
  lower <- apply(boot_betas, 2, function(x) quantile(x, probs = alpha / 2))
  upper <- apply(boot_betas, 2, function(x) quantile(x, probs = 1 - alpha / 2))

  return(data.frame(Lower = lower, Upper = upper))
}

## 3. Confusion Matrix and Evaluation Metrics
confusion_matrix_metrics <- function(y_true, y_pred, cutoff = 0.5) {
  # y_true: actual response values (0/1)
  # y_pred: predicted probabilities (between 0 and 1)
  # cutoff: threshold for converting predicted probabilities into class labels

  y_pred_class <- ifelse(y_pred > cutoff, 1, 0)

  # Confusion matrix components
  tp <- sum(y_true == 1 & y_pred_class == 1)
  tn <- sum(y_true == 0 & y_pred_class == 0)
  fp <- sum(y_true == 0 & y_pred_class == 1)
  fn <- sum(y_true == 1 & y_pred_class == 0)

  # Compute metrics
  prevalence <- (tp + fn) / length(y_true)
  accuracy <- (tp + tn) / length(y_true)
  sensitivity <- tp / (tp + fn)
  specificity <- tn / (tn + fp)
  fdr <- fp / (fp + tp)
  dor <- (tp * tn) / (fp * fn)

  return(list(
    ConfusionMatrix = matrix(c(tp, fp, fn, tn), nrow = 2),
    Prevalence = prevalence,
    Accuracy = accuracy,
    Sensitivity = sensitivity,
    Specificity = specificity,
    FalseDiscoveryRate = fdr,
    DiagnosticOddsRatio = dor
  ))
}
```


```{r}
covid <- read.csv("~/Documents/GitHub/Quiz2_Indrajit/covid.csv", header = TRUE, sep = ",")
head(covid)


```

