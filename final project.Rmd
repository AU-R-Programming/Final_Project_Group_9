---
title: "Final Project Group 9"
author: "Erika Richter, Indrajit Nandi, Waliu Lamidi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Final Project}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

# Overview

### This vignette demonstrates the functionality of the **binclass** package, which provides tools for logistic regression using numerical optimization, bootstrapped confidence intervals, and classification performance metrics.

## Example: Using `crop.data.csv`

### First, ensure the required dataset is loaded. The dataset should be in the working directory as `crop.data.csv`.

```{r setup, include = FALSE}
#knitr::opts_chunk$set(echo = TRUE)
library(devtools)
library(binclass)
```

## Load the dataset
```{r}
crop_data <- read.csv("crop.data.csv")
head(crop_data)

```


## Data Preperation and Logistic Regression Using Numerical Optimization
```{r}
 

X <- as.matrix(cbind(1, as.numeric(crop_data$density), 
                        as.numeric(crop_data$block), 
                        as.numeric(crop_data$fertilizer)))
y <- as.numeric(crop_data$yield) 



beta <- logistic_regression(X, y)
print(beta)

```

## Bootstrapped Confidence Intervals
### Compute bootstrapped confidence intervals
```{r}
ci <- bootstrap_CI(X, y, n_bootstrap = 100, alpha = 0.05)
print(ci)
```

## Confusion Matrix and Metrics
```{r}
# Simulate predicted probabilities for demonstration
set.seed(123)
y_pred <- runif(length(y))

# Compute confusion matrix and metrics
metrics <- confusion_matrix_metrics(y, y_pred, cutoff = 0.5)
print(metrics)
```

## Conclusion
### The FinalProjectGroup9 package provides robust tools for binary classification and performance evaluation using logistic regression. Use this vignette to understand its applications.



### Steps to Include the Vignette in Your Package

<!-- 1. **Save the File**: -->
<!--    Save the vignette file as `vignettes/FinalProject.Rmd` in your package directory. -->

<!-- 2. **Add Vignette Support**: -->
<!--    Run the following command to set up vignettes in your package: -->

<!--    ```R -->
<!--    usethis::use_vignette("FinalProject") -->
<!-- Build and Check: Build your package using: -->
<!-- R -->

<!-- devtools::build() -->
<!-- Check that the vignette renders correctly by running: -->
<!-- R -->

<!-- devtools::build_vignettes() -->
<!-- Install the Package: Install the package and view the vignette: -->
<!-- R -->

<!-- devtools::install() -->
<!-- browseVignettes("FinalProjectGroup9") -->




## This is redundant. Still adding here. 
```{r}



# Final Project

## Step 1: Created R package - complete (aka: binclass)


# Step 2: Implement Core Functionality

## 1. Logistic regression using numerical optimization
logistic_regression <- function(X, y, tol = 1e-6, max_iter = 100) {
  X_t <- t(X)
  beta_init <- tryCatch(
    solve(X_t %*% X) %*% X_t %*% y, 
    error = function(e) rep(0, ncol(X))
  )
  print(beta_init)  # Check initial beta values

  sigmoid <- function(x) {
    p <- 1 / (1 + exp(-x))
    p <- pmax(p, 1e-10)
    p <- pmin(p, 1 - 1e-10)
    return(p)
  }

  nll <- function(beta) {
    p <- sigmoid(X %*% beta)
    print(p)  # Check predicted probabilities
    -sum(y * log(p) + (1 - y) * log(1 - p))
  }

  gradient <- function(beta) {
    p <- sigmoid(X %*% beta)
    t(X) %*% (y - p)
  }

  result <- optim(
    beta_init, nll, gr = gradient, method = "BFGS", 
    control = list(maxit = max_iter, reltol = tol)
  )
  
  if (result$convergence != 0) warning("Optimization did not converge.")
  return(result$par)
}
## 2. Bootstrapped Confidence Intervals
bootstrap_CI <- function(X, y, n_bootstrap = 20, alpha = 0.05) {
  n <- nrow(X)
  boot_betas <- matrix(NA, nrow = n_bootstrap, ncol = ncol(X))

  for (i in 1:n_bootstrap) {
    sample_indices <- sample(1:n, replace = TRUE)
    X_boot <- X[sample_indices, , drop = FALSE]
    y_boot <- y[sample_indices]

    boot_betas[i, ] <- logistic_regression(X_boot, y_boot)
  }

  # Calculate the lower and upper percentiles for CI
  lower <- apply(boot_betas, 2, function(x) quantile(x, probs = alpha / 2))
  upper <- apply(boot_betas, 2, function(x) quantile(x, probs = 1 - alpha / 2))

  return(data.frame(Lower = lower, Upper = upper))
}
## 3. Confusion Matrix and Evaluation Metrics
confusion_matrix_metrics <- function(y_true, y_pred, cutoff = 0.5) {
  # y_true: actual response values (0/1)
  # y_pred: predicted probabilities (between 0 and 1)
  # cutoff: threshold for converting predicted probabilities into class labels

  y_pred_class <- ifelse(y_pred > cutoff, 1, 0)

  # Confusion matrix components
  tp <- sum(y_true == 1 & y_pred_class == 1)
  tn <- sum(y_true == 0 & y_pred_class == 0)
  fp <- sum(y_true == 0 & y_pred_class == 1)
  fn <- sum(y_true == 1 & y_pred_class == 0)

  # Compute metrics
  prevalence <- (tp + fn) / length(y_true)
  accuracy <- (tp + tn) / length(y_true)
  sensitivity <- tp / (tp + fn)
  specificity <- tn / (tn + fp)
  fdr <- fp / (fp + tp)
  dor <- (tp * tn) / (fp * fn)

  return(list(
    ConfusionMatrix = matrix(c(tp, fp, fn, tn), nrow = 2),
    Prevalence = prevalence,
    Accuracy = accuracy,
    Sensitivity = sensitivity,
    Specificity = specificity,
    FalseDiscoveryRate = fdr,
    DiagnosticOddsRatio = dor
  ))
}
```



