---
title: "Final Project Group 9"
author: "Erika Richter, Indrajit Nandi, Waliu Lamidi"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Final Project}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

# Overview

### This vignette demonstrates the functionality of the **binclass** package, which provides tools for logistic regression using numerical optimization, bootstrapped confidence intervals, and classification performance metrics.

## Example: Using `crop.data.csv`

### First, ensure the required dataset is loaded. The dataset should be in the working directory as `crop.data.csv`.

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
library(binclass)
```

## Load the dataset
```{r, message=FALSE}
crop_data <- read.csv("crop.data.csv")
head(crop_data)

```


## Data Preperation and Logistic Regression Using Numerical Optimization
```{r, message=FALSE}

X <- as.matrix(cbind(1, as.numeric(crop_data$density), 
                        as.numeric(crop_data$block), 
                        as.numeric(crop_data$fertilizer)))
y <- as.numeric(crop_data$yield) 



beta <- logistic_regression(X, y)
print(beta)

```

## Bootstrapped Confidence Intervals
### Compute bootstrapped confidence intervals
```{r, message=FALSE}
ci <- bootstrap_CI(X, y, n_bootstrap = 100, alpha = 0.05)
print(ci)
```

## Confusion Matrix and Metrics
```{r, message=FALSE}
# Simulate predicted probabilities for demonstration
set.seed(123)
y_pred <- runif(length(y))

# Compute confusion matrix and metrics
metrics <- confusion_matrix_metrics(y, y_pred, cutoff = 0.5)
print(metrics)
```

## Conclusion
### The FinalProjectGroup9 package provides robust tools for binary classification and performance evaluation using logistic regression. Use this vignette to understand its applications.



### Steps to Include the Vignette in Your Package

<!-- 1. **Save the File**: -->
<!--    Save the vignette file as `vignettes/FinalProject.Rmd` in your package directory. -->

<!-- 2. **Add Vignette Support**: -->
<!--    Run the following command to set up vignettes in your package: -->

<!--    ```R -->
<!--    usethis::use_vignette("FinalProject") -->
<!-- Build and Check: Build your package using: -->
<!-- R -->

<!-- devtools::build() -->
<!-- Check that the vignette renders correctly by running: -->
<!-- R -->

<!-- devtools::build_vignettes() -->
<!-- Install the Package: Install the package and view the vignette: -->
<!-- R -->

<!-- devtools::install() -->
<!-- browseVignettes("FinalProjectGroup9") -->




## This is redundant. Still adding here. 
```{r}



# Final Project

## Step 1: Created R package - complete (aka: binclass)


# Step 2: Implement Core Functionality

## 1. Logistic regression using numerical optimization
logistic_regression <- function(X, y, tol = 1e-6, max_iter = 100) {
  X_t <- t(X)
  beta_init <- tryCatch(
    solve(X_t %*% X) %*% X_t %*% y, 
    error = function(e) rep(0, ncol(X))
  )
  print(beta_init)  # Check initial beta values

  sigmoid <- function(x) {
    p <- 1 / (1 + exp(-x))
    p <- pmax(p, 1e-10)
    p <- pmin(p, 1 - 1e-10)
    return(p)
  }

  nll <- function(beta) {
    p <- sigmoid(X %*% beta)
    print(p)  # Check predicted probabilities
    -sum(y * log(p) + (1 - y) * log(1 - p))
  }

  gradient <- function(beta) {
    p <- sigmoid(X %*% beta)
    t(X) %*% (y - p)
  }

  result <- optim(
    beta_init, nll, gr = gradient, method = "BFGS", 
    control = list(maxit = max_iter, reltol = tol)
  )
  
  if (result$convergence != 0) warning("Optimization did not converge.")
  return(result$par)
}

## 2. Bootstrapped Confidence Intervals
bootstrap_CI <- function(X, y, n_bootstrap = 20, alpha = 0.05) {
  n <- nrow(X)
  boot_betas <- matrix(NA, nrow = n_bootstrap, ncol = ncol(X))

  for (i in 1:n_bootstrap) {
    sample_indices <- sample(1:n, replace = TRUE)
    X_boot <- X[sample_indices, , drop = FALSE]
    y_boot <- y[sample_indices]

    boot_betas[i, ] <- logistic_regression(X_boot, y_boot)
  }

  # Calculate the lower and upper percentiles for CI
  lower <- apply(boot_betas, 2, function(x) quantile(x, probs = alpha / 2))
  upper <- apply(boot_betas, 2, function(x) quantile(x, probs = 1 - alpha / 2))

  return(data.frame(Lower = lower, Upper = upper))
}

## 3. Confusion Matrix and Evaluation Metrics
confusion_matrix_metrics <- function(y_true, y_pred, cutoff = 0.5) {
  # y_true: actual response values (0/1)
  # y_pred: predicted probabilities (between 0 and 1)
  # cutoff: threshold for converting predicted probabilities into class labels

  y_pred_class <- ifelse(y_pred > cutoff, 1, 0)

  # Confusion matrix components
  tp <- sum(y_true == 1 & y_pred_class == 1)
  tn <- sum(y_true == 0 & y_pred_class == 0)
  fp <- sum(y_true == 0 & y_pred_class == 1)
  fn <- sum(y_true == 1 & y_pred_class == 0)

  # Compute metrics
  prevalence <- (tp + fn) / length(y_true)
  accuracy <- (tp + tn) / length(y_true)
  sensitivity <- tp / (tp + fn)
  specificity <- tn / (tn + fp)
  fdr <- fp / (fp + tp)
  dor <- (tp * tn) / (fp * fn)

  return(list(
    ConfusionMatrix = matrix(c(tp, fp, fn, tn), nrow = 2),
    Prevalence = prevalence,
    Accuracy = accuracy,
    Sensitivity = sensitivity,
    Specificity = specificity,
    FalseDiscoveryRate = fdr,
    DiagnosticOddsRatio = dor
  ))
}


```
## Add a Shiny App for interactive usage and build a pkgdown website
```{r}
usethis::use_pkgdown()
pkgdown::build_site()

```

```{r}
library(shiny)

# Define UI

ui <- fluidPage(
  titlePanel("Supervised Binary Classification Using Numerical Optimization"),
  
  sidebarLayout(
    sidebarPanel(
      fileInput("datafile", "Upload CSV File", accept = c(".csv")),
      selectInput("response", "Select Response Variable:", choices = NULL),
      selectizeInput("predictors", "Select Predictor Variables:", choices = NULL, multiple = TRUE),
      numericInput("bootstrap", "Number of Bootstrap Iterations (B):", value = 1000, min = 100),
      numericInput("alpha", "Significance Level (Alpha):", value = 0.05, min = 0.01, max = 0.1, step = 0.01),
      actionButton("run", "Run Binary Classification"),
      downloadButton("downloadResults", "Download Results")
    ),
    
    mainPanel(
      h3("Results"),
      tabsetPanel(
        tabPanel("Coefficients", tableOutput("coefficients")),
        tabPanel("Confidence Intervals", tableOutput("confidence_intervals")),
        tabPanel("Confusion Matrix", tableOutput("confusion_matrix")),
        tabPanel("Performance Metrics", tableOutput("performance_metrics"))
      )
    )
  )
)

# Define server logic
server <- function(input, output, session) {
  
  # Reactive to load data
  dataset <- reactive({
    req(input$datafile)
    read.csv(input$datafile$datapath)
  })
  
  # Update UI choices for variables
  observe({
    data <- dataset()
    updateSelectInput(session, "response", choices = colnames(data))
    updateSelectizeInput(session, "predictors", choices = colnames(data))
  })
  
  # Function to calculate logistic regression
  logistic_regression <- function(X, y, B = 20, alpha = 0.05) {
    # Create design matrix
    design <- cbind(rep(1, dim(X)[1]), X)
    
    # Initialize beta with least squares formula
    beta_init <- solve(t(design) %*% design) %*% t(design) %*% y
    
    # Define the negative log-likelihood
    neg_log_likelihood <- function(beta) {
      p <- 1 / (1 + exp(-design %*% beta))
      -sum(y * log(p) + (1 - y) * log(1 - p))
    }
    
    # Optimization using optim
    result <- optim(beta_init, neg_log_likelihood)
    
    # Bootstrap confidence intervals
    booth_data <- cbind(y, rep(1, nrow(X)), X)
    n <- nrow(booth_data)
    B_hat <- matrix(NA, nrow = B, ncol = ncol(booth_data) - 1)
    
    for (i in 1:B) {
      bdata <- as.matrix(booth_data[sample(1:n, n, replace = TRUE), ])
      Xs <- bdata[, 2:ncol(bdata)]
      ys <- bdata[, 1]
      beta_init2 <- solve(t(Xs) %*% Xs) %*% t(Xs) %*% ys
      boot_lm <- optim(beta_init2, neg_log_likelihood)
      B_hat[i, ] <- boot_lm$par
    }
    
    CI <- apply(B_hat, 2, function(x) quantile(x, c(alpha / 2, 1 - alpha / 2)))
    
    # Predict probabilities and evaluate performance
    p_hat <- 1 / (1 + exp(-design %*% result$par))
    y_pred <- ifelse(p_hat >= 0.5, 1, 0)
    
    true_positive <- sum(y == 1 & y_pred == 1)
    true_negative <- sum(y == 0 & y_pred == 0)
    false_positive <- sum(y == 0 & y_pred == 1)
    false_negative <- sum(y == 1 & y_pred == 0)
    
    confusion_matrix <- matrix(c(true_positive, false_negative, false_positive, true_negative), 
                               nrow = 2, 
                               dimnames = list(
                                 Actual = c("Positive", "Negative"),
                                 Predicted = c("Positive", "Negative")
                               ))
    
    accuracy <- (true_positive + true_negative) / length(y)
    sensitivity <- true_positive / (true_positive + false_negative)
    specificity <- true_negative / (true_negative + false_positive)
    
    return(list(
      beta = result$par,
      CI = CI,
      confusion_matrix = confusion_matrix,
      metrics = data.frame(
        Accuracy = accuracy,
        Sensitivity = sensitivity,
        Specificity = specificity
      )
    ))
  }
  
  # Run logistic regression and store results
  results <- eventReactive(input$run, {
    data <- dataset()
    X <- as.matrix(data[, input$predictors])
    y <- as.numeric(data[[input$response]])
    logistic_regression(X, y, B = input$bootstrap, alpha = input$alpha)
  })
  
  # Output results
  output$coefficients <- renderTable({
    req(results())
    data.frame(Coefficients = results()$beta)
  })
  
  output$confidence_intervals <- renderTable({
    req(results())
    CI <- results()$CI
    t(CI)
  })
  
  output$confusion_matrix <- renderTable({
    req(results())
    results()$confusion_matrix
  })
  
  output$performance_metrics <- renderTable({
    req(results())
    results()$metrics
  })
  
  # Download results
  output$downloadResults <- downloadHandler(
    filename = function() {
      paste("logistic_regression_results", Sys.Date(), ".csv", sep = "")
    },
    content = function(file) {
      req(results())
      write.csv(results()$metrics, file)
    }
  )
}

# Run the application 
shinyApp(ui = ui, server = server)

```
